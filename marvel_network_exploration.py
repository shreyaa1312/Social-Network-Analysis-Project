# -*- coding: utf-8 -*-
"""marvel-network-exploration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qw5amcQoIqU9BBhqrNULlKCDCVwYnqIP
"""

import pandas as pd #handle arrays in most efficient ways possible

hero_network_df = pd.read_csv("./hero-network.csv")

hero_network_df.head()

# strip spaces from hero names
hero_network_df["hero1"] = hero_network_df["hero1"].apply(lambda x: x.strip())
hero_network_df["hero2"] = hero_network_df["hero2"].apply(lambda x: x.strip())

hero_network_df.head()

# all_heroes contains each hero name once
all_heroes = set()

for row in hero_network_df.index:
    all_heroes.add(hero_network_df["hero1"][row])
    all_heroes.add(hero_network_df["hero2"][row])
    
print(len(all_heroes))
# all_heroes

from collections import defaultdict

# create an undirected graph (adjacency list) for use with BFS
# this does not show edge weights (no count of edges between characters)
undir_hero_map = defaultdict(set)

for row in hero_network_df.index:
    hero1 = hero_network_df["hero1"][row]
    hero2 = hero_network_df["hero2"][row]
    
    undir_hero_map[hero1].add(hero2)
    undir_hero_map[hero2].add(hero1)
    
print("There are {} Marvel characters in the dataset".format(len(undir_hero_map.keys())))
# undir_hero_map

# get the number of edges/links (not weighted)
# from undirected graph
total_num_edges = 0

for hero in undir_hero_map.keys():
    edge_length = len(undir_hero_map[hero])
    total_num_edges += edge_length
    
total_num_edges /= 2

total_num_edges

# export basic csv with hero name to edge count (first-degree relations)

ordered_heroes = list(all_heroes)

first_deg_df = pd.DataFrame(data={"hero":[hero for hero in ordered_heroes], "count":[len(undir_hero_map[hero]) for hero in ordered_heroes]})

first_deg_df.to_csv("./first_degree.csv", index=False)

first_deg_df = first_deg_df.sort_values(by='count', ascending=False)

#top 60 heroes by first-degree connections - most of these have appeared in movies already!
first_deg_df.head(60)

from collections import deque

# basic connectivity test - can do now that we have 
# the undirected adjacency list 

# test how many groups of heroes there are (connectivity)

# helper function that gives all heroes connected to a given hero
def basicBFS(hero, graph_map):
    queue = deque([hero])
    seen = set([hero])
    
    while(len(queue) > 0):
        curr_hero = queue.popleft()
        
        # add all first-degree heroes not in seen
        for adjacent_hero in graph_map[curr_hero]:
            if(adjacent_hero not in seen):
                queue.append(adjacent_hero)
                seen.add(adjacent_hero)
            
    
    return seen

# connectivity function - returns the number of heroes in each group and number of unconnected groups
def connectivity(hero_set, graph_map):
    all_groups = []
    all_seen = set()
    count = 0
    
    for hero in graph_map.keys():
        count += 1
        if(hero not in all_seen):
            hero_group = basicBFS(hero, graph_map)
            all_groups.append(len(hero_group))
            for connected_hero in hero_group:
                all_seen.add(connected_hero)
                
    print("Number of Groupings and Hero Count:", all_groups)
    print("Total Number of Heroes Seen (should match total hero count):", count)
                
    return all_groups

print(connectivity(all_heroes, undir_hero_map))

# basic BFS for getting hero degree of separation
# includes information about the links between the heroes specified

def hero_BFS(hero1, hero2, graph_map):    
    queue = deque()
    queue.append((hero1, [hero1]))
    seen = set([hero1])
    
    while(len(queue) > 0):
        curr_hero, hero_chain = queue.popleft()
        
        # if curr_hero is hero2, end loop
        if(curr_hero == hero2):
            return hero_chain
        
        # otherwise, add all unseen heroes to queue, with chain
        for new_hero in graph_map[curr_hero]:
            if(new_hero not in seen):
                new_hero_chain = hero_chain.copy()
                new_hero_chain.append(new_hero)
                
                queue.append((new_hero, new_hero_chain))
                
                seen.add(new_hero)
#     print(seen)
    return ["Not connected!"]
            
# test
hero_BFS('IRON MAN/TONY STARK', "EMPRESS S'BYLL [SKRU", undir_hero_map)

# basic BFS for getting all routes to hero at min. degree of separation
# includes information about the links between the heroes specified
# as an array of all possible paths

def all_paths_BFS(hero1, hero2, graph_map):    
    # stop at the minimum degree, and return all paths
    # that have hero2 as the last value
    min_degree = len(hero_BFS(hero1, hero2, graph_map))
    all_paths = []
    
    queue = deque()
    queue.append((hero1, [hero1]))
    seen = set([hero1])
    
    while(len(queue[0][1]) <= min_degree):
        curr_hero, hero_chain = queue.popleft()
        
        # if curr_hero is hero2, end loop
        if(curr_hero == hero2):
            all_paths.append(hero_chain)
        
        # otherwise, add all unseen heroes to queue, with chain
        for new_hero in graph_map[curr_hero]:
            if(new_hero not in seen or new_hero == hero2):
                new_hero_chain = hero_chain.copy()
                new_hero_chain.append(new_hero)
                
                queue.append((new_hero, new_hero_chain))
                
                seen.add(new_hero)
#     print(seen)
    return all_paths
            
# test
all_paths_BFS('LITTLE, ABNER', "FAITH", undir_hero_map)

import json

# output JSON version of all_paths output that is compatible with 
# a D3 sankey visualization -> https://www.d3-graph-gallery.com/graph/sankey_basic.html

def hero_paths_to_json(all_paths_arr):
    # degree of separation
    sep_degree = len(all_paths_arr[0])
    
    # all heroes present in the sankey, no duplicates
    heroes_seen = set([b for a in all_paths_arr for b in a])
    
    # index values are the node numbers in the json
    heroes_ordered = list(heroes_seen)
    
    # used for mapping hero names to indices - for output json
    hero_index_map = {}
    for i, hero in enumerate(heroes_ordered):
        hero_index_map[hero] = i
        
    # create nodes list of "objects" - first part of output json
    nodes = [{"name": hero, "node": i} for i, hero in enumerate(heroes_ordered)]
        
    # tuple dictionary for weighting flows/edges
    edge_dict = defaultdict(int)
    
    for arr in all_paths_arr:
        for i in range(sep_degree-1):
            from_hero = arr[i]
            to_hero = arr[i+1]
            edge_dict[(from_hero, to_hero)] += 1
        
    links = [{"source":hero_index_map[key[0]], "target":hero_index_map[key[1]], "value":value} for key, value in edge_dict.items()]
    
    output_to_json = {"nodes":nodes, "links":links}
    
    return output_to_json
    
test_sankey_json = hero_paths_to_json(all_paths_BFS('LITTLE, ABNER', "FAITH", undir_hero_map))

with open('sankey_data.json', 'w') as outfile:
    json.dump(test_sankey_json, outfile)

# json.dumps(test_sankey_json)

# max degrees of separation for a character

def maxSeparation(hero, graph_map):
    queue = deque()
    queue.append((hero, 0))
    seen = set([hero])
    
    while(len(queue) > 0):
        curr_hero, curr_distance = queue.popleft()
        
        # add all first-degree heroes not in seen
        for adjacent_hero in graph_map[curr_hero]:
            if(adjacent_hero not in seen):
                queue.append((adjacent_hero, curr_distance+1))
                seen.add(adjacent_hero)                
    
    return curr_distance

# test
maxSeparation("FAITH", undir_hero_map)

# calculate the maximum distance in the graph (width) - 
# by calculating the max number of degrees of separation for each character
# takes some time, so usually commented out after first file creation

# NOTE: the separate groups are not split up here - could look into that in the future!

hero_dist_map = defaultdict(int)

for hero in all_heroes:
    max_dist = maxSeparation(hero, undir_hero_map)
    hero_dist_map[hero] = max_dist
    
# hero_dist_map

# max degree of separation for Marvel characters
print("The maximum degree of separation in this network is:", max(hero_dist_map.values()))
print("The smallest maximum degree of separation in this network is:", min(hero_dist_map.values()))
print("The average maximum degree of separation in this network is:", sum(hero_dist_map[hero] for hero in all_heroes)/len(all_heroes))

# save graph distances to a file

max_dist_df = pd.DataFrame(data={"hero":ordered_heroes, "max_dist":[hero_dist_map[hero] for hero in ordered_heroes]})

max_dist_df.to_csv("./max_distances.csv", index=False)

print(max_dist_df.sort_values(by="max_dist", ascending=False).head())

max_dist_df.head()

# import max_dist_df if already created

max_dist_df = pd.read_csv("./max_distances.csv")

max_dist_df.head()

# heroes not part of the main network comprise the minimum max distances
# - 3 disconnected networksfrom main network!

max_dist_df.loc[max_dist_df["max_dist"] == 1]

print(hero_BFS("AMAZO-MAXI-WOMAN/", "FAITH", undir_hero_map))

# output all the Marvel characters to a json file

max_dist_df["hero"].to_json(path_or_buf='./names.json', orient="values")

!pip install igraph